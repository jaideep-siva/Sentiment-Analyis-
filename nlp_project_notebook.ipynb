{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kpbqYjd7E9e"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP5Wn3PpPEwx",
        "outputId": "ec8277fb-7009-408b-ca2d-e1ed0e6f156d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "import joblib\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import gensim\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers import Embedding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Dropout\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TweFazpmAjZ6",
        "outputId": "f09720eb-04ef-4ce4-ef28-a7c6dec0dc19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3Y6AqMv7H7r"
      },
      "source": [
        "Obtain raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2u7SQte601O"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://git.wayne.edu/gh7553/twitter_dataset_sentiment-analysis/-/raw/master/training.1600000.processed.noemoticon.csv',names=['target','ids','date','flag','user','raw_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6m9jEgxcoMr"
      },
      "source": [
        "Some EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MVjh9TMR7Srz",
        "outputId": "d7f33f6d-cc00-4278-9355-c47d0285fac8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-70b4d361-bae8-41f8-b6a4-71eb197ae099\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>raw_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70b4d361-bae8-41f8-b6a4-71eb197ae099')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70b4d361-bae8-41f8-b6a4-71eb197ae099 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70b4d361-bae8-41f8-b6a4-71eb197ae099');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   target         ids                          date      flag  \\\n",
              "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                           raw_text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUYxTdIObDFJ",
        "outputId": "740b4071-b7ba-44db-caf1-126f9fc9b4ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target      0\n",
              "ids         0\n",
              "date        0\n",
              "flag        0\n",
              "user        0\n",
              "raw_text    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PXXLbs2cE5v",
        "outputId": "4ac81b2f-e690-4cae-ff0d-2d412dae79cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1600000, 6)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzLnJg41cGqc",
        "outputId": "748bcdfb-6267-4a58-a388-0d800c7753dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1600000 entries, 0 to 1599999\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count    Dtype \n",
            "---  ------    --------------    ----- \n",
            " 0   target    1600000 non-null  int64 \n",
            " 1   ids       1600000 non-null  int64 \n",
            " 2   date      1600000 non-null  object\n",
            " 3   flag      1600000 non-null  object\n",
            " 4   user      1600000 non-null  object\n",
            " 5   raw_text  1600000 non-null  object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 73.2+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CfuI6iCZ2LG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "preprocessing steps for data\n",
        "\n",
        "1. remove links\n",
        "2. remove @'s\n",
        "3. lower-case all text\n",
        "4. remove puncuation\n",
        "5. remove stopwords\n",
        "6. tokenize words per row\n",
        "7. stem words per row\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rtl8BxU_ISK"
      },
      "outputs": [],
      "source": [
        "df['process_text'] = df['raw_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrYQ3taKcrcL"
      },
      "outputs": [],
      "source": [
        "#Remove Links and handles from the raw tweet data using regex\n",
        "def remove_links_and_handles(text):\n",
        "    pattern_links = r\"^[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$\"\n",
        "    text = re.sub(pattern_links, '', text)\n",
        "    pattern_handles = r'@[^\\s]+'\n",
        "    text = re.sub(pattern_handles, '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fpu7lQsFjvhn"
      },
      "outputs": [],
      "source": [
        "#remove puncuation from raw tweet data using regex\n",
        "def remove_punctuation(text):\n",
        "    pattern = r'[^\\w\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFf1uD8Jd5Vx"
      },
      "outputs": [],
      "source": [
        "#applying removing link and puncuation with making everything lowercase\n",
        "df['process_text'] = df['process_text'].apply(remove_links_and_handles)\n",
        "df['process_text'] = df['process_text'].apply(remove_punctuation)\n",
        "df['process_text'] = df['process_text'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_S9jUuNedkv",
        "outputId": "cd6d2e68-b5bb-40a0-d1e3-1b24b4aab41f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "print(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVMI6o91hjXq"
      },
      "outputs": [],
      "source": [
        "#tokenize the tweets\n",
        "df['process_text'] = df['process_text'].apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG6UbfgXiytd"
      },
      "outputs": [],
      "source": [
        "#remove stopwords that do not add any value in evaluation of sentiment for a tweet\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "    return filtered_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zwRQyUWVkq2X"
      },
      "outputs": [],
      "source": [
        "df['process_text'] = df['process_text'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "llbhqOb2lXC2",
        "outputId": "99d99681-604a-4622-e5f5-c62a12f8e476"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0          [httptwitpiccom2y1zl, awww, thats, bummer, sho...\n",
              "1          [upset, cant, update, facebook, texting, might...\n",
              "2          [dived, many, times, ball, managed, save, 50, ...\n",
              "3                    [whole, body, feels, itchy, like, fire]\n",
              "4                             [behaving, im, mad, cant, see]\n",
              "                                 ...                        \n",
              "1599995                  [woke, school, best, feeling, ever]\n",
              "1599996    [thewdbcom, cool, hear, old, walt, interviews,...\n",
              "1599997                [ready, mojo, makeover, ask, details]\n",
              "1599998    [happy, 38th, birthday, boo, alll, time, tupac...\n",
              "1599999                              [happy, charitytuesday]\n",
              "Name: process_text, Length: 1600000, dtype: object"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['process_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BoYu-9lb4oI6",
        "outputId": "6a7d78c4-d7a7-450a-ca98-17d3cf752d77"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e0e08d39-ea06-4450-9540-d436c64d50b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>process_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>[httptwitpiccom2y1zl, awww, thats, bummer, sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>[dived, many, times, ball, managed, save, 50, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>[behaving, im, mad, cant, see]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0e08d39-ea06-4450-9540-d436c64d50b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0e08d39-ea06-4450-9540-d436c64d50b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0e08d39-ea06-4450-9540-d436c64d50b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   target         ids                          date      flag  \\\n",
              "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                           raw_text  \\\n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
              "\n",
              "                                        process_text  \n",
              "0  [httptwitpiccom2y1zl, awww, thats, bummer, sho...  \n",
              "1  [upset, cant, update, facebook, texting, might...  \n",
              "2  [dived, many, times, ball, managed, save, 50, ...  \n",
              "3            [whole, body, feels, itchy, like, fire]  \n",
              "4                     [behaving, im, mad, cant, see]  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WWzex44mlZiB"
      },
      "outputs": [],
      "source": [
        "df.to_csv(r'./pre_processed_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VbjgoeUClwS7"
      },
      "outputs": [],
      "source": [
        "#easy access to new data post processing\n",
        "pre_processed_data = pd.read_csv('https://git.wayne.edu/gh7553/twitter_dataset_sentiment-analysis/-/raw/master/pre_processed_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GFWKVk85oBNO",
        "outputId": "aa2fc83f-897d-43f5-e157-8449d218dd20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4044979d-8ba4-4c9b-8aad-cafe0996c1ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>process_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>['httptwitpiccom2y1zl', 'awww', 'thats', 'bumm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>['upset', 'cant', 'update', 'facebook', 'texti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>['dived', 'many', 'times', 'ball', 'managed', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>['whole', 'body', 'feels', 'itchy', 'like', 'f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>['behaving', 'im', 'mad', 'cant', 'see']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4044979d-8ba4-4c9b-8aad-cafe0996c1ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4044979d-8ba4-4c9b-8aad-cafe0996c1ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4044979d-8ba4-4c9b-8aad-cafe0996c1ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   target         ids                          date      flag  \\\n",
              "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                           raw_text  \\\n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
              "\n",
              "                                        process_text  \n",
              "0  ['httptwitpiccom2y1zl', 'awww', 'thats', 'bumm...  \n",
              "1  ['upset', 'cant', 'update', 'facebook', 'texti...  \n",
              "2  ['dived', 'many', 'times', 'ball', 'managed', ...  \n",
              "3  ['whole', 'body', 'feels', 'itchy', 'like', 'f...  \n",
              "4           ['behaving', 'im', 'mad', 'cant', 'see']  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pre_processed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vFShcydlN_GU",
        "outputId": "a05844f7-b175-41ef-9b03-189763ecc038"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    800000\n",
              "1    800000\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Change the binary \"target\" values to (0,1)\n",
        "\n",
        "pre_processed_data['target'] = pre_processed_data['target'].replace(4,1)\n",
        "\n",
        "pre_processed_data['target'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxQ8LDzcPCiB"
      },
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lxpRTtH4PCq9"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eda_df = pre_processed_data\n",
        "eda_df.columns\n",
        "sns.countplot(data = eda_df, x = 'target')\n",
        "plt.title(\"Count Plot of target class\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEcOyS5LSFoS"
      },
      "source": [
        "> There appears to be no class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vuZQnn8VS0bX"
      },
      "outputs": [],
      "source": [
        "eda_df.head()\n",
        "eda_df['target'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW3JtGwBTmJ0"
      },
      "source": [
        "Word Cloud Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jw1O87w7TKqQ"
      },
      "outputs": [],
      "source": [
        "#creating a list with postive words for word cloud\n",
        "positive_list= []\n",
        "positive = eda_df[eda_df['target'] == 1]\n",
        "positive_list.append(positive['process_text'])\n",
        "\n",
        "negative_list = []\n",
        "negative = eda_df[eda_df['target'] == 0]\n",
        "negative_list.append(negative['process_text'])\n",
        "\n",
        "# Joining all words in the list\n",
        "positive_all = \" \".join([word for sent in positive_list for word in sent ])\n",
        "negative_all = \" \".join([word for sent in negative_list for word in sent ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yNBZASMmT_O-"
      },
      "outputs": [],
      "source": [
        "# Importing Word Cloud Package\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "#Creating a word cloud object for postive words\n",
        "wordcloud = WordCloud(width=2000,height=1000,background_color='#000000',max_words = 500).generate(positive_all)\n",
        "\n",
        "#plotting Postive word cloud\n",
        "plt.figure(figsize=(20,30))\n",
        "plt.imshow(wordcloud)\n",
        "plt.title(\"Recursive Positive Words\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nmpa4SOabMwQ"
      },
      "outputs": [],
      "source": [
        "#Creating word cloud object for negative words\n",
        "wordcloud = WordCloud(width=2000,height=1000,background_color='#000000',max_words = 500).generate(negative_all)\n",
        "\n",
        "#Plotting negative word cloud\n",
        "plt.figure(figsize=(20,30))\n",
        "plt.imshow(wordcloud)\n",
        "plt.title(\"Recursive Negative Words\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X47kGEfJ8Mc3"
      },
      "source": [
        "Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KC4M6UE-KPMh"
      },
      "outputs": [],
      "source": [
        "# Split Test/Train Data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pre_processed_data[\"process_text\"], pre_processed_data[\"target\"], test_size=0.3, random_state=39)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "840ZNl9bLrpa"
      },
      "outputs": [],
      "source": [
        "# Vectorize Data\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IVIH56hAMALu"
      },
      "outputs": [],
      "source": [
        "# LOGISTIC REGRESSION MODEL\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr.score(X_test, y_test)\n",
        "\n",
        "\n",
        "print(\"F1 Score: \", f1_score(y_test, lr.predict(X_test)))\n",
        "print('Accuracy: ', accuracy_score(y_test, lr.predict(X_test)), \"\\n\")\n",
        "print(classification_report(y_test, lr.predict(X_test)))\n",
        "print('Confusion Matrix:\\n', confusion_matrix(y_test, lr.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter tuning\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameters to be tuned\n",
        "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "          'penalty': ['l1', 'l2']}\n",
        "\n",
        "# Use GridSearchCV to search for the best hyperparameters\n",
        "grid_search = GridSearchCV(lr, params, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and corresponding accuracy score\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best accuracy score: \", grid_search.best_score_)\n",
        "\n",
        "# Use the best hyperparameters to make predictions on the test set\n",
        "best_lr = grid_search.best_estimator_\n",
        "print(\"F1 Score: \", f1_score(y_test, best_lr.predict(X_test)))\n",
        "print('Accuracy: ', accuracy_score(y_test, best_lr.predict(X_test)), \"\\n\")\n",
        "print(classification_report(y_test, best_lr.predict(X_test)))\n",
        "print('Confusion Matrix:\\n', confusion_matrix(y_test, best_lr.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "4yap4L2rT3q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvalvCxZl-ZD"
      },
      "source": [
        "LSTM Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOZuNGhYl-ZE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# convert the \"process_text\" column to a string with spaces\n",
        "pre_processed_data['string_text'] = pre_processed_data['process_text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# print the updated dataframe\n",
        "pre_processed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTG3E8Dll-ZF"
      },
      "outputs": [],
      "source": [
        "#splitting into testing/training\n",
        "X_train, X_test, y_train, y_test = train_test_split(pre_processed_data[\"string_text\"], pre_processed_data[\"target\"], test_size=0.3, random_state=39)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ScX0Db_kl-ZG"
      },
      "outputs": [],
      "source": [
        "pre_processed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nGHrxs_yl-ZG"
      },
      "outputs": [],
      "source": [
        "#tokenizing data\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train.values)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary Size :\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jwv6pO7Hl-ZH"
      },
      "outputs": [],
      "source": [
        "# Sequence padding on text\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(X_train.values),\n",
        "                        maxlen = 30)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(X_test.values),\n",
        "                       maxlen = 30)\n",
        "\n",
        "print(\"Training X Shape:\",x_train.shape)\n",
        "print(\"Testing X Shape:\",x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xkiUUrBml-ZH"
      },
      "outputs": [],
      "source": [
        "# Getting y values in a readable shape\n",
        "y_train = y_train.values.reshape(-1,1)\n",
        "y_test = y_test.values.reshape(-1,1)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiaAwsJKl-ZI",
        "outputId": "341e7932-828f-439b-d8e4-3e2fc688a491"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-29 06:36:50--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-29 06:36:50--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-29 06:36:50--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.08MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-29 06:39:29 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "#loading in GloVe embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DxLvTqr4l-ZJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Setting parameterings\n",
        "GLOVE_EMB = 'glove.6B.300d.txt'\n",
        "EMBEDDING_DIM = 300\n",
        "LR = 1e-3\n",
        "MODEL_PATH = 'best_model.hdf5'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4IErydtPl-ZK",
        "outputId": "41b3f76d-a089-409d-a5a2-6c019810c5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "#loading embeddings\n",
        "embeddings_index = {}\n",
        "\n",
        "f = open(GLOVE_EMB)\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = value = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(embeddings_index))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h3tbHkXtl-ZL"
      },
      "outputs": [],
      "source": [
        "# Creating embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DzP5FD_zl-ZM"
      },
      "outputs": [],
      "source": [
        "# Setting embedding layer for LSTM\n",
        "embedding_layer = tf.keras.layers.Embedding(vocab_size,\n",
        "                                          EMBEDDING_DIM,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          input_length=30,\n",
        "                                          trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S2ZiUk-0l-ZN"
      },
      "outputs": [],
      "source": [
        "# Creating parameters for LSTM\n",
        "# Define input shape & embeddings\n",
        "sequence_input = Input(shape=(30,), dtype='int32')\n",
        "embedding_sequences = embedding_layer(sequence_input)\n",
        "#  Spatial Dropout layer\n",
        "x = SpatialDropout1D(0.2)(embedding_sequences)\n",
        "# dense layer with ReLU\n",
        "x = Conv1D(64, 5, activation='relu')(x)\n",
        "# Bidirection LSTM\n",
        "x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
        "# Dense layer with 512 with ReLU\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Dropout layer to prevent overfitting\n",
        "x = Dropout(0.5)(x)\n",
        "# Another dense layer\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# 1D Output layer\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "#Defining model\n",
        "model = tf.keras.Model(sequence_input, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4n5Tlj8Vl-ZO"
      },
      "outputs": [],
      "source": [
        "# Setting loss function and other NN parameters\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=LR), loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1,\n",
        "                                     min_lr = 0.01,\n",
        "                                     monitor = 'val_loss',\n",
        "                                     verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "PEaE68Wol-ZO",
        "outputId": "1e02e621-072d-4100-aafb-5b8c36dbba0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1400/1400 [==============================] - 1344s 956ms/step - loss: 0.5890 - accuracy: 0.6764 - val_loss: 0.5548 - val_accuracy: 0.7047 - lr: 0.0010\n",
            "Epoch 2/10\n",
            " 710/1400 [==============>...............] - ETA: 10:07 - loss: 0.5565 - accuracy: 0.7076"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-38130d372cb0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(x_train, y_train, batch_size= 800, epochs=10,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Training LSTM\n",
        "history = model.fit(x_train, y_train, batch_size= 800, epochs=10,\n",
        "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCLMpxwfl-ZQ"
      },
      "outputs": [],
      "source": [
        "# Plotting LSTM validation accuracy\n",
        "s, (at, al) = plt.subplots(2,1)\n",
        "at.plot(history.history['accuracy'], c= 'b')\n",
        "at.plot(history.history['val_accuracy'], c='r')\n",
        "at.set_title('model accuracy')\n",
        "at.set_ylabel('accuracy')\n",
        "at.set_xlabel('epoch')\n",
        "at.legend(['LSTM_train', 'LSTM_val'], loc='upper left')\n",
        "\n",
        "al.plot(history.history['loss'], c='m')\n",
        "al.plot(history.history['val_loss'], c='c')\n",
        "al.set_title('model loss')\n",
        "al.set_ylabel('loss')\n",
        "al.set_xlabel('epoch')\n",
        "al.legend(['train', 'val'], loc = 'upper left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8O3nNiQvmPd"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwkzGlSQ8eAa"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRIM THE DATA TO 10% IN ORDER TO RUN CODE WITHOUT RUNNING OUT OF MEMORY AND COMPUTING POWER\n",
        "df_sampled = pre_processed_data.sample(frac=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "R8Ka6ByVUD4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPLIT DATA INTO TRAIN/TEST\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_sampled[\"process_text\"], df_sampled[\"target\"], test_size=0.3, random_state=39)"
      ],
      "metadata": {
        "id": "ZtzKExChUF5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6yjz1pqqslt"
      },
      "outputs": [],
      "source": [
        "# SVM MODEL\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# Define a custom tokenizer function\n",
        "def my_tokenizer(text):\n",
        "    tokens = text.lower().split()  # Split text into words\n",
        "    return tokens\n",
        "\n",
        "# Convert text data into numerical features using TF-IDF representation\n",
        "vectorizer = TfidfVectorizer(tokenizer=my_tokenizer)\n",
        "\n",
        "X_train_list = X_train.tolist()\n",
        "X_test_list = X_test.tolist()\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_list)\n",
        "X_test_tfidf = vectorizer.transform(X_test_list)\n",
        "\n",
        "svc_model = SVC()\n",
        "svc_model.fit(X_train_tfidf, y_train)\n",
        "y_pred = svc_model.predict(X_test_tfidf)\n",
        "\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "print(test_acc)\n",
        "\n",
        "svc_cfm = confusion_matrix(y_test, y_pred)\n",
        "print(svc_cfm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXIll0wxFb19"
      },
      "source": [
        "HYPER-PARAMETER TUNERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKBt0kT0FgEZ"
      },
      "outputs": [],
      "source": [
        "#GRID HYPERPARAMETER SEARCH\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "\n",
        "grid_search = GridSearchCV(svc_model, param_grid, cv=5)\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eixw8N7NFvDF"
      },
      "outputs": [],
      "source": [
        "#RANDOM HYPERPARAMETER SEARCH\n",
        "from scipy.stats import loguniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distributions = {'C': loguniform(0.1, 1, 10), 'kernel': ['linear', 'rbf']}\n",
        "random_search = RandomizedSearchCV(svc_model, param_distributions, n_iter=10, cv=5)\n",
        "random_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "best_params_random = random_search.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqzh0GM_ZnJv"
      },
      "outputs": [],
      "source": [
        "#BAYES HYPERPARAMETER SEARCH\n",
        "\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "param_space = {'C': (0.1, 10.0, 'log-uniform'),\n",
        "               'kernel': ['linear', 'rbf'],\n",
        "               'gamma': (1e-6, 1e+1, 'log-uniform'),\n",
        "               'degree': (1, 8, 'uniform')}\n",
        "\n",
        "opt = BayesSearchCV(svc_model, param_space, n_iter=50, cv=5, n_jobs=-1)\n",
        "opt.fit(X_train_tfidf, y_train)\n",
        "\n",
        "best_params_bayes = opt.best_params_\n",
        "\n",
        "best_svm = SVC(**best_params_bayes)\n",
        "best_svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "accuracy = best_svm.score(X_test_tfidf, y_test)\n",
        "print(\"Best SVM :\", best_params_bayes)\n",
        "print(\"Accuracy :\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeNYbQfFG13m"
      },
      "source": [
        "Bag of Words/ Term Frequiency\n",
        "-only count so does not capture the order in which the words go in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjlNa0bZFn6w"
      },
      "outputs": [],
      "source": [
        "x = pre_processed_data.process_text\n",
        "y = pre_processed_data.target\n",
        "\n",
        "vect = CountVectorizer()\n",
        "vect.fit(x_train)\n",
        "CountVectorizer()\n",
        "\n",
        "\n",
        "vect_tunned = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=0.1, max_df=0.7, max_features=100)\n",
        "vect_tunned\n",
        "CountVectorizer(max_df=0.7, max_features=100, min_df=0.1, ngram_range=(1, 2),\n",
        "                stop_words='english')\n",
        "\n",
        "model = SVC(kernel='linear', random_state = 10)\n",
        "model.fit(x_train_dtm, y_train)\n",
        "#predicting output for test data\n",
        "pred = model.predict(x_test_dtm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzc3TRMBoS3Y"
      },
      "source": [
        "Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnpqPotkoSsn"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Training Model\n",
        "rfc=RandomForestClassifier(n_estimators=200,criterion=\"entropy\")\n",
        "rfc.fit(X_train,y_train)\n",
        "y_pred=rfc.predict(X_test)\n",
        "\n",
        "#Model Metrics\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"The test accuracy score of Random Forest Classificatoin is: {:<.2f}% \\n\".format( accuracy_score(y_test, y_pred)*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjAUrvnGoaFI"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfJzTWyioZpc"
      },
      "outputs": [],
      "source": [
        "#Installing Packages\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score\n",
        "from sklearn import tree\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "#Model Creation\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "#Model Mertics\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(\"The test accuracy score of Decision Tree is: {:<.2f}% \\n\".format( accuracy_score(y_test, y_pred)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftcnNYimocnR"
      },
      "source": [
        "XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WRZdxUbob9X"
      },
      "outputs": [],
      "source": [
        "#Importing Packages\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "#Model Creation\n",
        "xg =XGBClassifier()\n",
        "xg.fit(X_train,y_train)\n",
        "y_pred= xg.predict(X_test)\n",
        "\n",
        "#Model Metrics\n",
        "print(\"The test accuracy score of XGBoost is: {:<.2f}% \\n\".format( accuracy_score(y_test, y_pred)*100))\n",
        "print(classification_report(y_test,y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}